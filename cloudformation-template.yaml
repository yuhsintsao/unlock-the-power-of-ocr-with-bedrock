AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for event-driven GenAI IDP application'

Parameters:
  BedrockModelId:
    Type: String
    Description: 'Bedrock model ID to be used in the SageMaker processing job'
    Default: 'anthropic.claude-3-sonnet-20240229-v1:0'
  ECRRepositoryUri:
    Type: String
    Description: 'The public URI of the container image stored in Amazon Elastic Container Registry (ECR). Used to specify the custom environment for the SageMaker processing job.'
    Default: '<account-id>.dkr.ecr.<region>.amazonaws.com/idp-fm-processing:latest'

Resources:
  # S3 Buckets
  InputBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-input-v1-${AWS::AccountId}-${AWS::Region}'
      NotificationConfiguration:
        EventBridgeConfiguration:
          EventBridgeEnabled: true

  ScriptBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-script-v1-${AWS::AccountId}-${AWS::Region}'

  OutputBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-output-v1-${AWS::AccountId}-${AWS::Region}'

  # IAM Roles and Policies
  SageMakerExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${InputBucket}'
                  - !Sub 'arn:aws:s3:::${InputBucket}/*'
                  - !Sub 'arn:aws:s3:::${ScriptBucket}'
                  - !Sub 'arn:aws:s3:::${ScriptBucket}/*'
                  - !Sub 'arn:aws:s3:::${OutputBucket}'
                  - !Sub 'arn:aws:s3:::${OutputBucket}/*'
        - PolicyName: BedrockAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                Resource: !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/${BedrockModelId}'

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: SageMakerAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - sagemaker:CreateProcessingJob
                  - sagemaker:DescribeProcessingJob
                Resource: !Sub 'arn:aws:sagemaker:${AWS::Region}:${AWS::AccountId}:processing-job/*'
              - Effect: Allow
                Action:
                  - sagemaker:ListProcessingJobs
                Resource: '*'
        - PolicyName: PassRole
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - iam:PassRole
                Resource: !GetAtt SageMakerExecutionRole.Arn
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${InputBucket}'
                  - !Sub 'arn:aws:s3:::${InputBucket}/*'
                  - !Sub 'arn:aws:s3:::${ScriptBucket}'
                  - !Sub 'arn:aws:s3:::${ScriptBucket}/*'
                  - !Sub 'arn:aws:s3:::${OutputBucket}'
                  - !Sub 'arn:aws:s3:::${OutputBucket}/*'

  # EventBridge Rule
  EventBridgeRule:
    Type: AWS::Events::Rule
    Properties:
      EventPattern:
        source:
          - aws.s3
        detail-type:
          - 'Object Created'
        detail:
          bucket:
            name:
              - !Ref InputBucket
          object:
            key:
              - prefix: ''
      State: ENABLED
      Targets:
        - Arn: !GetAtt TriggerProcessingJobLambda.Arn
          Id: "TriggerProcessingJobLambdaTarget"

  LambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref TriggerProcessingJobLambda
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn: !GetAtt EventBridgeRule.Arn

  # Lambda Function to Trigger SageMaker Processing Job
  TriggerProcessingJobLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import boto3
          import os
          import json
          import uuid
          import time
          from datetime import datetime, timedelta
          from dateutil.tz import tzutc

          def is_processing_job_running(sagemaker_client):
              response = sagemaker_client.list_processing_jobs(
                  StatusEquals='InProgress',
                  MaxResults=1
              )
              return len(response['ProcessingJobSummaries']) > 0

          def lambda_handler(event, context):
              s3_client = boto3.client('s3')
              sagemaker_client = boto3.client('sagemaker')
              current_region = os.environ['AWS_REGION']

              input_bucket = os.environ['INPUT_BUCKET']
              script_bucket = os.environ['SCRIPT_BUCKET']
              output_bucket = os.environ['OUTPUT_BUCKET']
              role_arn = os.environ['SAGEMAKER_ROLE_ARN']
              model_id = os.environ['BEDROCK_MODEL_ID']
              ecr_image_uri = os.environ['ECR_IMAGE_URI']

              # Check if a processing job is already running
              if is_processing_job_running(sagemaker_client):
                  print("A processing job is already running. Skipping this trigger.")
                  return

              # Generate a unique job name using the current timestamp and a UUID
              timestamp = datetime.utcnow().strftime('%Y%m%d%H%M%S')
              unique_id = str(uuid.uuid4().hex)
              job_name = f"processing-job-{timestamp}-{unique_id}"

              response = sagemaker_client.create_processing_job(
                  ProcessingJobName=job_name,
                  RoleArn=role_arn,
                  AppSpecification={
                      'ImageUri': ecr_image_uri,
                      'ContainerEntrypoint': ['python3', '/opt/ml/processing/script/start.py'],
                  },
                  ProcessingInputs=[
                      {
                          'InputName': 'input-data',
                          'S3Input': {
                              'S3Uri': f's3://{input_bucket}',
                              'LocalPath': '/opt/ml/processing/input',
                              'S3DataType': 'S3Prefix',
                              'S3InputMode': 'File',
                              'S3DataDistributionType': 'FullyReplicated',
                              'S3CompressionType': 'None'
                          }
                      },
                      {
                          'InputName': 'code',
                          'S3Input': {
                              'S3Uri': f's3://{script_bucket}',
                              'LocalPath': '/opt/ml/processing/script',
                              'S3DataType': 'S3Prefix',
                              'S3InputMode': 'File',
                              'S3DataDistributionType': 'FullyReplicated',
                              'S3CompressionType': 'None'
                          }
                      }
                  ],
                  ProcessingOutputConfig={
                      'Outputs': [
                          {
                              'OutputName': 'output-data',
                              'S3Output': {
                                  'S3Uri': f's3://{output_bucket}',
                                  'LocalPath': '/opt/ml/processing/output',
                                  'S3UploadMode': 'EndOfJob'
                              }
                          }
                      ]
                  },
                  StoppingCondition={
                      'MaxRuntimeInSeconds': 3600,
                  },
                  ProcessingResources={
                      'ClusterConfig': {
                          'InstanceCount': 1,
                          'InstanceType': 'ml.m5.xlarge',
                          'VolumeSizeInGB': 30
                      }
                  },
                  Environment={
                      'BEDROCK_MODEL_ID': model_id,
                      'AWS_REGION': current_region
                  }
              )

              print(f"Processing job started: {json.dumps(response, indent=2)}")
              return {
                  'statusCode': 200,
                  'body': json.dumps('Processing job started successfully')
              }
      Runtime: python3.12
      Timeout: 300
      Environment:
        Variables:
          INPUT_BUCKET: !Ref InputBucket
          SCRIPT_BUCKET: !Ref ScriptBucket
          OUTPUT_BUCKET: !Ref OutputBucket
          SAGEMAKER_ROLE_ARN: !GetAtt SageMakerExecutionRole.Arn
          BEDROCK_MODEL_ID: !Ref BedrockModelId
          ECR_IMAGE_URI: !Ref ECRRepositoryUri

Outputs:
  InputBucketName:
    Description: 'Name of the input S3 bucket'
    Value: !Ref InputBucket
  OutputBucketName:
    Description: 'Name of the output S3 bucket'
    Value: !Ref OutputBucket
  ScriptBucketName:
    Description: 'Name of the script S3 bucket'
    Value: !Ref ScriptBucket
  LambdaFunctionArn:
    Description: 'ARN of the Lambda function'
    Value: !GetAtt TriggerProcessingJobLambda.Arn
  SageMakerRoleArn:
    Description: 'ARN of the SageMaker execution role'
    Value: !GetAtt SageMakerExecutionRole.Arn
